{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Install required packages\n",
        "!pip install gradio nemo_toolkit[asr] torch torchaudio librosa soundfile\n",
        "\n",
        "import gradio as gr\n",
        "import nemo.collections.asr as nemo_asr\n",
        "import torch\n",
        "import torchaudio\n",
        "import librosa\n",
        "import soundfile as sf\n",
        "import os\n",
        "import tempfile\n",
        "import re\n",
        "from typing import Optional, Tuple\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "class ParakeetASRInterface:\n",
        "    def __init__(self):\n",
        "        self.current_model = None\n",
        "        self.current_model_name = None\n",
        "\n",
        "    def extract_model_name_from_url(self, url_or_name: str) -> str:\n",
        "        \"\"\"Extract model name from Hugging Face URL or return the name directly.\"\"\"\n",
        "        if url_or_name.startswith(\"https://huggingface.co/\"):\n",
        "            # Extract model name from URL\n",
        "            pattern = r\"https://huggingface\\.co/([^/]+/[^/?]+)\"\n",
        "            match = re.match(pattern, url_or_name)\n",
        "            if match:\n",
        "                return match.group(1)\n",
        "            else:\n",
        "                raise ValueError(\"Invalid Hugging Face URL format\")\n",
        "        else:\n",
        "            # Assume it's already a model name\n",
        "            return url_or_name.strip()\n",
        "\n",
        "    def load_model(self, model_url_or_name: str) -> Tuple[str, str]:\n",
        "        \"\"\"Load a Parakeet model from Hugging Face.\"\"\"\n",
        "        try:\n",
        "            model_name = self.extract_model_name_from_url(model_url_or_name)\n",
        "\n",
        "            # Check if model is already loaded\n",
        "            if self.current_model is not None and self.current_model_name == model_name:\n",
        "                return f\"‚úÖ Model '{model_name}' is already loaded and ready!\", \"\"\n",
        "\n",
        "            # Clear previous model\n",
        "            if self.current_model is not None:\n",
        "                del self.current_model\n",
        "                torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
        "\n",
        "            # Load new model\n",
        "            status_msg = f\"üîÑ Loading model '{model_name}'...\"\n",
        "            print(status_msg)\n",
        "\n",
        "            self.current_model = nemo_asr.models.ASRModel.from_pretrained(model_name=model_name)\n",
        "            self.current_model_name = model_name\n",
        "\n",
        "            # Move to GPU if available\n",
        "            if torch.cuda.is_available():\n",
        "                self.current_model = self.current_model.cuda()\n",
        "                device_info = \"GPU\"\n",
        "            else:\n",
        "                device_info = \"CPU\"\n",
        "\n",
        "            success_msg = f\"‚úÖ Successfully loaded '{model_name}' on {device_info}!\"\n",
        "            return success_msg, \"\"\n",
        "\n",
        "        except Exception as e:\n",
        "            error_msg = f\"‚ùå Error loading model: {str(e)}\"\n",
        "            return error_msg, \"\"\n",
        "\n",
        "    def transcribe_audio(self, audio_input, decoder_type: str = \"TDT\") -> Tuple[str, str]:\n",
        "        \"\"\"Transcribe audio using the loaded model.\"\"\"\n",
        "        try:\n",
        "            if self.current_model is None:\n",
        "                return \"‚ùå Please load a model first!\", \"\"\n",
        "\n",
        "            if audio_input is None:\n",
        "                return \"‚ùå Please provide an audio file!\", \"\"\n",
        "\n",
        "            # Handle different audio input types\n",
        "            if isinstance(audio_input, tuple):\n",
        "                sample_rate, audio_data = audio_input\n",
        "                # Save temporary file\n",
        "                with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as tmp_file:\n",
        "                    sf.write(tmp_file.name, audio_data, sample_rate)\n",
        "                    audio_path = tmp_file.name\n",
        "            else:\n",
        "                # Assume it's a file path\n",
        "                audio_path = audio_input\n",
        "\n",
        "            # Load and preprocess audio\n",
        "            audio_data, sr = librosa.load(audio_path, sr=16000, mono=True)\n",
        "\n",
        "            # Save preprocessed audio\n",
        "            with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as tmp_file:\n",
        "                sf.write(tmp_file.name, audio_data, 16000)\n",
        "                processed_audio_path = tmp_file.name\n",
        "\n",
        "            # Set decoder type\n",
        "            if hasattr(self.current_model, 'change_decoding_strategy'):\n",
        "                if decoder_type.upper() == \"CTC\":\n",
        "                    # For CTC decoding\n",
        "                    self.current_model.change_decoding_strategy(decoder_type=\"ctc\")\n",
        "                else:\n",
        "                    # For TDT decoding (default)\n",
        "                    self.current_model.change_decoding_strategy(decoder_type=\"tdt\")\n",
        "\n",
        "            # Transcribe\n",
        "            status_msg = f\"üîÑ Transcribing audio using {decoder_type} decoder...\"\n",
        "            print(status_msg)\n",
        "\n",
        "            transcriptions = self.current_model.transcribe([processed_audio_path])\n",
        "\n",
        "            if transcriptions and len(transcriptions) > 0:\n",
        "                if hasattr(transcriptions[0], 'text'):\n",
        "                    result = transcriptions[0].text\n",
        "                else:\n",
        "                    result = str(transcriptions[0])\n",
        "            else:\n",
        "                result = \"No transcription generated\"\n",
        "\n",
        "            # Cleanup temporary files\n",
        "            try:\n",
        "                if isinstance(audio_input, tuple):\n",
        "                    os.unlink(audio_path)\n",
        "                os.unlink(processed_audio_path)\n",
        "            except:\n",
        "                pass\n",
        "\n",
        "            success_msg = f\"‚úÖ Transcription completed using {decoder_type} decoder!\"\n",
        "            return result, success_msg\n",
        "\n",
        "        except Exception as e:\n",
        "            error_msg = f\"‚ùå Error during transcription: {str(e)}\"\n",
        "            return \"\", error_msg\n",
        "\n",
        "# Initialize the interface\n",
        "asr_interface = ParakeetASRInterface()\n",
        "\n",
        "# Define the Gradio interface\n",
        "def create_gradio_interface():\n",
        "    with gr.Blocks(\n",
        "        title=\"ü¶ú Parakeet ASR - Hugging Face Models\",\n",
        "        theme=gr.themes.Soft()\n",
        "    ) as interface:\n",
        "\n",
        "        gr.Markdown(\"\"\"\n",
        "        # ü¶ú Parakeet Automatic Speech Recognition\n",
        "\n",
        "        Use NVIDIA's Parakeet models from Hugging Face for speech recognition!\n",
        "\n",
        "        **Instructions:**\n",
        "        1. Enter a Hugging Face model URL or model name (e.g., `nvidia/parakeet-tdt_ctc-0.6b-ja`)\n",
        "        2. Click \"Load Model\"\n",
        "        3. Upload or record audio\n",
        "        4. Choose decoder type (TDT or CTC)\n",
        "        5. Click \"Transcribe\"\n",
        "        \"\"\")\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=2):\n",
        "                model_input = gr.Textbox(\n",
        "                    label=\"ü§ó Hugging Face Model URL or Name\",\n",
        "                    placeholder=\"nvidia/parakeet-tdt_ctc-0.6b-ja\",\n",
        "                    value=\"nvidia/parakeet-tdt_ctc-0.6b-ja\",\n",
        "                    info=\"Enter the full HF URL or just the model name\"\n",
        "                )\n",
        "\n",
        "                load_btn = gr.Button(\"üîÑ Load Model\", variant=\"primary\")\n",
        "\n",
        "                model_status = gr.Textbox(\n",
        "                    label=\"Model Status\",\n",
        "                    interactive=False,\n",
        "                    placeholder=\"No model loaded\"\n",
        "                )\n",
        "\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=1):\n",
        "                audio_input = gr.Audio(\n",
        "                    label=\"üé§ Audio Input\",\n",
        "                    type=\"filepath\",\n",
        "                    format=\"wav\"\n",
        "                )\n",
        "\n",
        "                decoder_choice = gr.Radio(\n",
        "                    choices=[\"TDT\", \"CTC\"],\n",
        "                    value=\"TDT\",\n",
        "                    label=\"üîß Decoder Type\",\n",
        "                    info=\"TDT is generally faster, CTC might be more accurate\"\n",
        "                )\n",
        "\n",
        "                transcribe_btn = gr.Button(\"üéØ Transcribe Audio\", variant=\"secondary\")\n",
        "\n",
        "            with gr.Column(scale=1):\n",
        "                transcription_output = gr.Textbox(\n",
        "                    label=\"üìù Transcription Result\",\n",
        "                    lines=6,\n",
        "                    placeholder=\"Transcription will appear here...\",\n",
        "                    interactive=False\n",
        "                )\n",
        "\n",
        "                transcribe_status = gr.Textbox(\n",
        "                    label=\"Transcription Status\",\n",
        "                    interactive=False,\n",
        "                    placeholder=\"Ready for transcription\"\n",
        "                )\n",
        "\n",
        "        # Example models section\n",
        "        gr.Markdown(\"\"\"\n",
        "        ## üìö Example Parakeet Models\n",
        "\n",
        "        Click on any model name to load it:\n",
        "        \"\"\")\n",
        "\n",
        "        example_models = [\n",
        "            \"nvidia/parakeet-tdt_ctc-0.6b-ja\",\n",
        "            \"nvidia/parakeet-ctc-0.6b\",\n",
        "            \"nvidia/parakeet-tdt-1.1b\",\n",
        "            \"nvidia/parakeet-ctc-1.1b\"\n",
        "        ]\n",
        "\n",
        "        with gr.Row():\n",
        "            for model in example_models:\n",
        "                gr.Button(\n",
        "                    model.split(\"/\")[-1],\n",
        "                    size=\"sm\"\n",
        "                ).click(\n",
        "                    lambda m=model: m,\n",
        "                    outputs=model_input\n",
        "                )\n",
        "\n",
        "        # Event handlers\n",
        "        load_btn.click(\n",
        "            fn=asr_interface.load_model,\n",
        "            inputs=[model_input],\n",
        "            outputs=[model_status, gr.Textbox(visible=False)]\n",
        "        )\n",
        "\n",
        "        transcribe_btn.click(\n",
        "            fn=asr_interface.transcribe_audio,\n",
        "            inputs=[audio_input, decoder_choice],\n",
        "            outputs=[transcription_output, transcribe_status]\n",
        "        )\n",
        "\n",
        "        # Footer\n",
        "        gr.Markdown(\"\"\"\n",
        "        ---\n",
        "\n",
        "        **Notes:**\n",
        "        - Models are loaded from Hugging Face and may take time to download initially\n",
        "        - Audio is automatically resampled to 16kHz mono as required by Parakeet models\n",
        "        - TDT decoder is typically faster but CTC might provide better accuracy in some cases\n",
        "        - Make sure you have sufficient GPU memory for larger models\n",
        "\n",
        "        **Supported formats:** WAV, MP3, FLAC, M4A\n",
        "        \"\"\")\n",
        "\n",
        "    return interface\n",
        "\n",
        "# Launch the interface\n",
        "if __name__ == \"__main__\":\n",
        "    # Create and launch the interface\n",
        "    interface = create_gradio_interface()\n",
        "\n",
        "    # Launch with public sharing enabled for Colab\n",
        "    interface.launch(\n",
        "        share=True,  # Creates a public link\n",
        "        debug=True,  # Shows detailed error messages\n",
        "        server_name=\"0.0.0.0\",  # Allows external connections\n",
        "        server_port=7860,  # Default Gradio port\n",
        "        show_error=True\n",
        "    )"
      ],
      "metadata": {
        "id": "GVV95yzzvr0H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
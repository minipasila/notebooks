{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BOA94oX8uR_i"
      },
      "outputs": [],
      "source": [
        "# Maya1 Text-to-Speech - Google Colab Version\n",
        "# Run each cell in order\n",
        "\n",
        "# ========== CELL 1: Install Dependencies ==========\n",
        "\"\"\"\n",
        "Install required packages\n",
        "\"\"\"\n",
        "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install -q gradio soundfile accelerate\n",
        "!pip install -q git+https://github.com/huggingface/transformers\n",
        "!pip install -q git+https://github.com/hubertsiuzdak/snac\n",
        "\n",
        "print(\"‚úÖ All dependencies installed!\")\n",
        "\n",
        "# ========== CELL 2: Import Libraries ==========\n",
        "\"\"\"\n",
        "Import required libraries\n",
        "\"\"\"\n",
        "import gradio as gr\n",
        "import torch\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "from snac import SNAC\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "import tempfile\n",
        "\n",
        "print(f\"‚úÖ Libraries imported!\")\n",
        "print(f\"üîß GPU Available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"üéÆ GPU: {torch.cuda.get_device_name(0)}\")\n",
        "\n",
        "# ========== CELL 3: Load Models ==========\n",
        "\"\"\"\n",
        "Load Maya1 and SNAC models\n",
        "This may take a few minutes on first run\n",
        "\"\"\"\n",
        "print(\"üì¶ Loading Maya1 model...\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"maya-research/maya1\",\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\n",
        "    \"maya-research/maya1\",\n",
        "    trust_remote_code=True\n",
        ")\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "print(\"üéµ Loading SNAC audio decoder...\")\n",
        "snac_model = SNAC.from_pretrained(\"hubertsiuzdak/snac_24khz\").eval()\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "model.to(device)\n",
        "snac_model.to(device)\n",
        "\n",
        "print(f\"‚úÖ Models loaded on {device}!\")\n",
        "\n",
        "# ========== CELL 4: Define Generation Function ==========\n",
        "\"\"\"\n",
        "Speech generation function\n",
        "\"\"\"\n",
        "def generate_speech(text, voice_description):\n",
        "    \"\"\"Generate speech from text using Maya1 model\"\"\"\n",
        "\n",
        "    if not text.strip():\n",
        "        raise gr.Error(\"Please enter some text to convert to speech!\")\n",
        "\n",
        "    if not voice_description.strip():\n",
        "        voice_description = \"Realistic voice with neutral tone and conversational pacing.\"\n",
        "\n",
        "    try:\n",
        "        # Create prompt\n",
        "        prompt = f'<description=\"{voice_description}\"> {text}'\n",
        "\n",
        "        # Tokenize input\n",
        "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(device)\n",
        "\n",
        "        # Generate\n",
        "        with torch.inference_mode():\n",
        "            outputs = model.generate(\n",
        "                input_ids=inputs['input_ids'],\n",
        "                attention_mask=inputs.get('attention_mask', None),\n",
        "                max_new_tokens=1000,\n",
        "                temperature=0.7,\n",
        "                top_p=0.9,\n",
        "                do_sample=True,\n",
        "                pad_token_id=tokenizer.pad_token_id,\n",
        "                eos_token_id=None,\n",
        "            )\n",
        "\n",
        "        # Extract SNAC audio tokens\n",
        "        generated_ids = outputs[0, inputs['input_ids'].shape[1]:]\n",
        "        snac_tokens = [t.item() for t in generated_ids if 128266 <= t <= 156937]\n",
        "\n",
        "        if len(snac_tokens) < 7:\n",
        "            raise gr.Error(\n",
        "                f\"Not enough audio tokens generated ({len(snac_tokens)}). \"\n",
        "                f\"Try using longer text or different voice description.\"\n",
        "            )\n",
        "\n",
        "        # Decode SNAC tokens to audio frames\n",
        "        frames = len(snac_tokens) // 7\n",
        "        codes = [[], [], []]\n",
        "\n",
        "        for i in range(frames):\n",
        "            s = snac_tokens[i*7:(i+1)*7]\n",
        "            codes[0].append((s[0]-128266) % 4096)\n",
        "            codes[1].extend([(s[1]-128266) % 4096, (s[4]-128266) % 4096])\n",
        "            codes[2].extend([\n",
        "                (s[2]-128266) % 4096,\n",
        "                (s[3]-128266) % 4096,\n",
        "                (s[5]-128266) % 4096,\n",
        "                (s[6]-128266) % 4096\n",
        "            ])\n",
        "\n",
        "        # Generate final audio with SNAC decoder\n",
        "        codes_tensor = [\n",
        "            torch.tensor(c, dtype=torch.long, device=device).unsqueeze(0)\n",
        "            for c in codes\n",
        "        ]\n",
        "\n",
        "        with torch.inference_mode():\n",
        "            audio = snac_model.decoder(\n",
        "                snac_model.quantizer.from_codes(codes_tensor)\n",
        "            )[0, 0].cpu().numpy()\n",
        "\n",
        "        # Save to temporary file\n",
        "        with tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\") as f:\n",
        "            sf.write(f.name, audio, 24000)\n",
        "            return f.name\n",
        "\n",
        "    except Exception as e:\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        raise gr.Error(f\"Error generating speech: {str(e)}\")\n",
        "\n",
        "print(\"‚úÖ Generation function defined!\")\n",
        "\n",
        "# ========== CELL 5: Create and Launch Gradio UI ==========\n",
        "\"\"\"\n",
        "Create and launch the Gradio interface\n",
        "\"\"\"\n",
        "# Examples\n",
        "examples = [\n",
        "    [\n",
        "        \"Hello! This is Maya1 <laugh> the best open source voice AI model with emotions.\",\n",
        "        \"Realistic male voice in the 30s age with american accent. Normal pitch, warm timbre, conversational pacing.\"\n",
        "    ],\n",
        "    [\n",
        "        \"I'm so excited to share this amazing news with you! This is incredible and wonderful!\",\n",
        "        \"Energetic female voice with enthusiastic tone. Higher pitch, bright timbre, upbeat pacing.\"\n",
        "    ],\n",
        "    [\n",
        "        \"In a world of constant change, one thing remains certain: the power of human connection and understanding.\",\n",
        "        \"Deep male voice with authoritative tone. Low pitch, resonant timbre, steady pacing.\"\n",
        "    ],\n",
        "]\n",
        "\n",
        "# Create Gradio interface\n",
        "with gr.Blocks(theme=gr.themes.Soft(), title=\"Maya1 Text-to-Speech\") as demo:\n",
        "    gr.Markdown(\n",
        "        \"\"\"\n",
        "        # üéôÔ∏è Maya1 Text-to-Speech\n",
        "        Generate emotional and realistic speech with natural language voice design\n",
        "\n",
        "        **Running on Google Colab** | [Original Space](https://huggingface.co/spaces/akhaliq/maya1)\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            text_input = gr.Textbox(\n",
        "                label=\"Text to Speak\",\n",
        "                placeholder=\"Enter your text here... You can use <laugh>, <sigh>, and other emotion tags!\",\n",
        "                lines=5,\n",
        "                value=\"Hello! This is Maya1 <laugh> the best open source voice AI model with emotions.\"\n",
        "            )\n",
        "\n",
        "            voice_description = gr.Textbox(\n",
        "                label=\"Voice Description\",\n",
        "                placeholder=\"Describe the voice characteristics (age, gender, accent, pitch, timbre, pacing)...\",\n",
        "                lines=3,\n",
        "                value=\"Realistic male voice in the 30s age with american accent. Normal pitch, warm timbre, conversational pacing.\"\n",
        "            )\n",
        "\n",
        "            generate_btn = gr.Button(\"üé§ Generate Speech\", variant=\"primary\", size=\"lg\")\n",
        "\n",
        "        with gr.Column():\n",
        "            audio_output = gr.Audio(\n",
        "                label=\"Generated Speech\",\n",
        "                type=\"filepath\"\n",
        "            )\n",
        "\n",
        "            gr.Markdown(\"\"\"\n",
        "            ### üí° Tips\n",
        "            - Use emotion tags: `<laugh>`, `<laugh_harder>`, `<sigh>`, `<chuckle>`, `<gasp>`, `<angry>`, `<excited>`, `<whisper>`, `<cry>`, `<scream>`, `<sing>`, `<snort>`, `<exhale>`, `<gulp>`, `<giggle>`, `<sarcastic>`, `<curious>`\n",
        "            - Describe voice with: age, gender, accent, pitch, timbre, pacing\n",
        "            - Longer text works better (20+ words recommended)\n",
        "\n",
        "            ### About\n",
        "            Maya1 is an open-source voice AI model that generates realistic, emotional speech from text using natural language voice descriptions.\n",
        "\n",
        "            ### üìù Note\n",
        "            First generation may take longer as the model warms up. Subsequent generations will be faster.\n",
        "            \"\"\")\n",
        "\n",
        "    # Generate speech button\n",
        "    generate_btn.click(\n",
        "        fn=generate_speech,\n",
        "        inputs=[text_input, voice_description],\n",
        "        outputs=[audio_output]\n",
        "    )\n",
        "\n",
        "    # Examples section\n",
        "    gr.Examples(\n",
        "        examples=examples,\n",
        "        inputs=[text_input, voice_description],\n",
        "        outputs=[audio_output],\n",
        "        fn=generate_speech,\n",
        "        cache_examples=False,\n",
        "        label=\"Example Prompts\"\n",
        "    )\n",
        "\n",
        "# Launch with public URL\n",
        "demo.launch(share=True, debug=True)\n",
        "print(\"‚úÖ Gradio UI launched! Click the public URL above to access it.\")"
      ]
    }
  ]
}
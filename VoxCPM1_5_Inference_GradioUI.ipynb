{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kKMut7-2alsU"
      },
      "outputs": [],
      "source": [
        "# @title 1. Install Dependencies\n",
        "# Install the main library and UI tools\n",
        "!pip install -q voxcpm modelscope gradio soundfile torch torchaudio torchcodec\n",
        "\n",
        "# Install ffmpeg for audio processing\n",
        "!apt-get install -y ffmpeg\n",
        "\n",
        "print(\"Dependencies installed. Please run the next cell.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 2. Load Model (Fixed)\n",
        "import os\n",
        "import torch\n",
        "import soundfile as sf\n",
        "import numpy as np\n",
        "from modelscope import snapshot_download\n",
        "\n",
        "# --- THE FIX ---\n",
        "# We monkeypatch torch.compile to prevent the CUDA Graph crash.\n",
        "# This forces the model to run in standard (Eager) mode.\n",
        "def no_op_compile(model, *args, **kwargs):\n",
        "    print(f\"Skipping compilation for {type(model).__name__} to prevent Colab crash.\")\n",
        "    return model\n",
        "\n",
        "torch.compile = no_op_compile\n",
        "# ----------------\n",
        "\n",
        "from voxcpm import VoxCPM\n",
        "\n",
        "# Check for GPU\n",
        "if not torch.cuda.is_available():\n",
        "    raise SystemError(\"GPU not found. Please go to Runtime -> Change runtime type -> T4 GPU\")\n",
        "\n",
        "print(\"Downloading and loading VoxCPM1.5... (This may take a minute)\")\n",
        "\n",
        "# 1. Download/Load Main Model\n",
        "try:\n",
        "    # Initialize the model\n",
        "    model = VoxCPM.from_pretrained(\"openbmb/VoxCPM1.5\")\n",
        "    print(\"‚úÖ VoxCPM1.5 Loaded successfully (Eager Mode).\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading model: {e}\")\n",
        "\n",
        "# 2. Download Helper Models (for Denoising support)\n",
        "try:\n",
        "    print(\"Downloading ZipEnhancer for denoising support...\")\n",
        "    snapshot_download('iic/speech_zipenhancer_ans_multiloss_16k_base')\n",
        "    snapshot_download('iic/SenseVoiceSmall')\n",
        "    print(\"‚úÖ Helper models downloaded.\")\n",
        "except Exception as e:\n",
        "    print(f\"Warning: Could not download helper models. Denoising might not work. Error: {e}\")\n",
        "\n",
        "print(\"System Ready.\")"
      ],
      "metadata": {
        "id": "aNUrhoWAan2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 3. Run Gradio Interface\n",
        "import gradio as gr\n",
        "import uuid\n",
        "\n",
        "def generate_speech(\n",
        "    text,\n",
        "    prompt_audio,\n",
        "    prompt_text,\n",
        "    cfg_value,\n",
        "    inference_timesteps,\n",
        "    normalize,\n",
        "    denoise\n",
        "):\n",
        "    # Create a unique filename for the output\n",
        "    output_filename = f\"output_{uuid.uuid4()}.wav\"\n",
        "\n",
        "    prompt_path = None\n",
        "\n",
        "    # Handle Prompt Audio (Voice Cloning)\n",
        "    if prompt_audio is not None:\n",
        "        # Gradio passes audio as (sample_rate, data) or filepath depending on config.\n",
        "        # VoxCPM expects a filepath.\n",
        "        if isinstance(prompt_audio, str):\n",
        "            prompt_path = prompt_audio\n",
        "        else:\n",
        "            # If it's a tuple, save it temporarily\n",
        "            sr, data = prompt_audio\n",
        "            prompt_path = f\"temp_prompt_{uuid.uuid4()}.wav\"\n",
        "            sf.write(prompt_path, data, sr)\n",
        "\n",
        "    print(f\"Generating: '{text[:30]}...' | CFG: {cfg_value} | Steps: {inference_timesteps}\")\n",
        "\n",
        "    try:\n",
        "        # Run Generation\n",
        "        wav = model.generate(\n",
        "            text=text,\n",
        "            prompt_wav_path=prompt_path,\n",
        "            prompt_text=prompt_text if prompt_text and prompt_text.strip() != \"\" else None,\n",
        "            cfg_value=float(cfg_value),\n",
        "            inference_timesteps=int(inference_timesteps),\n",
        "            normalize=normalize,\n",
        "            denoise=denoise,\n",
        "            retry_badcase=True\n",
        "        )\n",
        "\n",
        "        # Save output\n",
        "        sf.write(output_filename, wav, model.tts_model.sample_rate)\n",
        "\n",
        "        # Cleanup temp prompt if created\n",
        "        if prompt_path and prompt_path != prompt_audio:\n",
        "            if os.path.exists(prompt_path):\n",
        "                os.remove(prompt_path)\n",
        "\n",
        "        return output_filename\n",
        "\n",
        "    except Exception as e:\n",
        "        raise gr.Error(f\"Generation failed: {str(e)}\")\n",
        "\n",
        "# Define the UI Layout\n",
        "with gr.Blocks(title=\"VoxCPM 1.5 Demo\", theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\n",
        "        \"\"\"\n",
        "        # üéôÔ∏è VoxCPM 1.5\n",
        "        **Tokenizer-Free TTS for Context-Aware Speech Generation and True-to-Life Voice Cloning**\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            # Input Section\n",
        "            txt_input = gr.Textbox(\n",
        "                label=\"Text to Speak\",\n",
        "                placeholder=\"Enter text here (English or Chinese)...\",\n",
        "                lines=3,\n",
        "                value=\"VoxCPM is an innovative end-to-end TTS model designed to generate highly expressive speech.\"\n",
        "            )\n",
        "\n",
        "            with gr.Accordion(\"Voice Cloning (Optional)\", open=True):\n",
        "                gr.Markdown(\"*Upload a short audio clip (3-10s) to clone the voice.*\")\n",
        "                audio_prompt = gr.Audio(\n",
        "                    label=\"Reference Audio\",\n",
        "                    type=\"filepath\",\n",
        "                    sources=[\"upload\", \"microphone\"]\n",
        "                )\n",
        "                txt_prompt = gr.Textbox(\n",
        "                    label=\"Reference Text (Optional)\",\n",
        "                    placeholder=\"Transcription of the reference audio. Improves cloning accuracy.\",\n",
        "                    info=\"If left empty, the model attempts to infer it, but providing text is better.\"\n",
        "                )\n",
        "\n",
        "            with gr.Accordion(\"Advanced Settings\", open=False):\n",
        "                slider_cfg = gr.Slider(\n",
        "                    minimum=1.0, maximum=5.0, value=2.0, step=0.1,\n",
        "                    label=\"CFG Value\",\n",
        "                    info=\"Higher = follows text/prompt closer. Lower = more expressive/random.\"\n",
        "                )\n",
        "                slider_steps = gr.Slider(\n",
        "                    minimum=5, maximum=50, value=10, step=1,\n",
        "                    label=\"Inference Timesteps\",\n",
        "                    info=\"Higher = better quality, slower speed.\"\n",
        "                )\n",
        "                chk_normalize = gr.Checkbox(\n",
        "                    label=\"Normalize Text\",\n",
        "                    value=False,\n",
        "                    info=\"Enable for standard text. Disable if using phonemes {HH AH0...}.\"\n",
        "                )\n",
        "                chk_denoise = gr.Checkbox(\n",
        "                    label=\"Denoise Prompt\",\n",
        "                    value=False,\n",
        "                    info=\"Removes noise from reference audio, but restricts output to 16kHz.\"\n",
        "                )\n",
        "\n",
        "            btn_gen = gr.Button(\"Generate Speech\", variant=\"primary\")\n",
        "\n",
        "        with gr.Column():\n",
        "            # Output Section\n",
        "            audio_out = gr.Audio(label=\"Generated Audio\")\n",
        "\n",
        "    # Connect function\n",
        "    btn_gen.click(\n",
        "        fn=generate_speech,\n",
        "        inputs=[\n",
        "            txt_input,\n",
        "            audio_prompt,\n",
        "            txt_prompt,\n",
        "            slider_cfg,\n",
        "            slider_steps,\n",
        "            chk_normalize,\n",
        "            chk_denoise\n",
        "        ],\n",
        "        outputs=[audio_out]\n",
        "    )\n",
        "\n",
        "# Launch\n",
        "demo.launch(share=True, debug=True)"
      ],
      "metadata": {
        "id": "-fdAggipapV9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFDYx7_kDXzP"
      },
      "outputs": [],
      "source": [
        "# Marvis TTS - Enhanced Gradio Interface with Streaming and Voice Cloning\n",
        "# Install required packages\n",
        "!pip install -U transformers gradio soundfile librosa numpy torch\n",
        "\n",
        "import torch\n",
        "import gradio as gr\n",
        "import soundfile as sf\n",
        "import librosa\n",
        "import numpy as np\n",
        "import tempfile\n",
        "import os\n",
        "from transformers import AutoTokenizer, AutoProcessor, CsmForConditionalGeneration\n",
        "from tokenizers.processors import TemplateProcessing\n",
        "import threading\n",
        "import time\n",
        "from typing import Generator, Optional, Tuple\n",
        "import io\n",
        "from pathlib import Path\n",
        "import datetime\n",
        "\n",
        "class MarvisTTSInterface:\n",
        "    def __init__(self):\n",
        "        self.model_id = \"Marvis-AI/marvis-tts-0.25m-v0.1-transformers\"\n",
        "        self.device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        self.processor = None\n",
        "        self.model = None\n",
        "        self.is_loaded = False\n",
        "        # Create output directory for saving files\n",
        "        self.output_dir = \"marvis_tts_outputs\"\n",
        "        os.makedirs(self.output_dir, exist_ok=True)\n",
        "\n",
        "    def save_audio_file(self, audio_data: np.ndarray, sample_rate: int = 24000, prefix: str = \"marvis\") -> str:\n",
        "        \"\"\"Save audio to a file and return the path\"\"\"\n",
        "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        filename = f\"{prefix}_{timestamp}.wav\"\n",
        "        filepath = os.path.join(self.output_dir, filename)\n",
        "\n",
        "        # Ensure audio is in the right format\n",
        "        if len(audio_data.shape) > 1:\n",
        "            audio_data = audio_data.squeeze()\n",
        "\n",
        "        # Normalize audio to prevent clipping\n",
        "        if np.max(np.abs(audio_data)) > 0:\n",
        "            audio_data = audio_data / np.max(np.abs(audio_data)) * 0.95\n",
        "\n",
        "        sf.write(filepath, audio_data, sample_rate, subtype=\"PCM_16\")\n",
        "        return filepath\n",
        "\n",
        "    def load_model(self):\n",
        "        \"\"\"Load the Marvis TTS model and processor\"\"\"\n",
        "        if self.is_loaded:\n",
        "            return \"Model already loaded!\"\n",
        "\n",
        "        try:\n",
        "            print(\"Loading Marvis TTS model...\")\n",
        "            self.processor = AutoProcessor.from_pretrained(self.model_id)\n",
        "            self.model = CsmForConditionalGeneration.from_pretrained(self.model_id).to(self.device)\n",
        "            self.is_loaded = True\n",
        "            return f\"‚úÖ Model loaded successfully on {self.device}!\"\n",
        "        except Exception as e:\n",
        "            return f\"‚ùå Error loading model: {str(e)}\"\n",
        "\n",
        "    def preprocess_audio(self, audio_file: str, target_length: float = 10.0) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Preprocess reference audio for voice cloning\n",
        "        Args:\n",
        "            audio_file: Path to audio file\n",
        "            target_length: Target length in seconds for voice reference\n",
        "        \"\"\"\n",
        "        try:\n",
        "            # Load audio file\n",
        "            audio, sr = librosa.load(audio_file, sr=24000)\n",
        "\n",
        "            # Ensure audio is the right length (10 seconds for optimal voice cloning)\n",
        "            target_samples = int(target_length * sr)\n",
        "\n",
        "            if len(audio) > target_samples:\n",
        "                # Trim to target length\n",
        "                audio = audio[:target_samples]\n",
        "            elif len(audio) < target_samples:\n",
        "                # Pad with silence if too short\n",
        "                padding = target_samples - len(audio)\n",
        "                audio = np.pad(audio, (0, padding), mode='constant', constant_values=0)\n",
        "\n",
        "            # Normalize audio\n",
        "            audio = audio / np.max(np.abs(audio))\n",
        "\n",
        "            return audio\n",
        "        except Exception as e:\n",
        "            raise ValueError(f\"Error preprocessing audio: {str(e)}\")\n",
        "\n",
        "    def generate_basic_tts(self, text: str, speaker_id: int = 0) -> Tuple[int, np.ndarray]:\n",
        "        \"\"\"Generate TTS without voice cloning\"\"\"\n",
        "        if not self.is_loaded:\n",
        "            raise ValueError(\"Model not loaded. Please load the model first.\")\n",
        "\n",
        "        try:\n",
        "            # Clear any cached states to prevent contamination\n",
        "            torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
        "\n",
        "            # Add speaker ID to text\n",
        "            formatted_text = f\"[{speaker_id}]{text}\"\n",
        "\n",
        "            # Prepare inputs\n",
        "            inputs = self.processor(formatted_text, add_special_tokens=True, return_tensors=\"pt\").to(self.device)\n",
        "\n",
        "            # Generate audio with fresh state\n",
        "            with torch.no_grad():\n",
        "                audio = self.model.generate(\n",
        "                    input_ids=inputs['input_ids'],\n",
        "                    output_audio=True,\n",
        "                    do_sample=True,\n",
        "                    temperature=0.7,\n",
        "                    pad_token_id=self.processor.tokenizer.eos_token_id\n",
        "                )\n",
        "\n",
        "            # Convert to numpy and ensure proper shape\n",
        "            audio_np = audio[0].cpu().numpy()\n",
        "            if len(audio_np.shape) > 1:\n",
        "                audio_np = audio_np.squeeze()\n",
        "\n",
        "            return 24000, audio_np\n",
        "\n",
        "        except Exception as e:\n",
        "            raise ValueError(f\"Error generating TTS: {str(e)}\")\n",
        "\n",
        "    def estimate_audio_duration(self, text: str) -> float:\n",
        "        \"\"\"Estimate audio duration based on text length (roughly 150 words per minute)\"\"\"\n",
        "        word_count = len(text.split())\n",
        "        return (word_count / 150) * 60  # Convert to seconds\n",
        "\n",
        "    def smart_text_chunker(self, text: str, max_duration: float = 8.0) -> list:\n",
        "        \"\"\"Split text into chunks that won't exceed max_duration seconds\"\"\"\n",
        "        sentences = text.replace('!', '.').replace('?', '.').split('.')\n",
        "        chunks = []\n",
        "        current_chunk = \"\"\n",
        "\n",
        "        for sentence in sentences:\n",
        "            sentence = sentence.strip()\n",
        "            if not sentence:\n",
        "                continue\n",
        "\n",
        "            # Test if adding this sentence would exceed duration limit\n",
        "            test_chunk = current_chunk + (\" \" if current_chunk else \"\") + sentence + \".\"\n",
        "            if self.estimate_audio_duration(test_chunk) > max_duration and current_chunk:\n",
        "                # Save current chunk and start new one\n",
        "                chunks.append(current_chunk.strip())\n",
        "                current_chunk = sentence + \".\"\n",
        "            else:\n",
        "                current_chunk = test_chunk\n",
        "\n",
        "        # Add the last chunk if it exists\n",
        "        if current_chunk.strip():\n",
        "            chunks.append(current_chunk.strip())\n",
        "\n",
        "        return chunks\n",
        "\n",
        "    def generate_streaming_tts(self, text: str, speaker_id: int = 0) -> Generator[Tuple[int, np.ndarray], None, None]:\n",
        "        \"\"\"Generate streaming TTS with proper chunking\"\"\"\n",
        "        if not self.is_loaded:\n",
        "            raise ValueError(\"Model not loaded. Please load the model first.\")\n",
        "\n",
        "        try:\n",
        "            # Clear any cached states\n",
        "            torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
        "\n",
        "            # Split text into chunks that won't exceed ~8 seconds\n",
        "            chunks = self.smart_text_chunker(text, max_duration=8.0)\n",
        "\n",
        "            for chunk in chunks:\n",
        "                if chunk.strip():\n",
        "                    # Generate audio for this chunk\n",
        "                    formatted_text = f\"[{speaker_id}]{chunk}\"\n",
        "                    inputs = self.processor(formatted_text, add_special_tokens=True, return_tensors=\"pt\").to(self.device)\n",
        "\n",
        "                    with torch.no_grad():\n",
        "                        audio = self.model.generate(\n",
        "                            input_ids=inputs['input_ids'],\n",
        "                            output_audio=True,\n",
        "                            do_sample=True,\n",
        "                            temperature=0.7\n",
        "                        )\n",
        "\n",
        "                    audio_np = audio[0].cpu().numpy()\n",
        "                    if len(audio_np.shape) > 1:\n",
        "                        audio_np = audio_np.squeeze()\n",
        "\n",
        "                    yield 24000, audio_np\n",
        "\n",
        "        except Exception as e:\n",
        "            raise ValueError(f\"Error in streaming TTS: {str(e)}\")\n",
        "\n",
        "    def generate_voice_cloned_tts(self, text: str, reference_audio: str) -> Tuple[int, np.ndarray]:\n",
        "        \"\"\"\n",
        "        Generate TTS with voice cloning using reference audio\n",
        "        Note: Simplified approach - real voice cloning would need model fine-tuning\n",
        "        \"\"\"\n",
        "        if not self.is_loaded:\n",
        "            raise ValueError(\"Model not loaded. Please load the model first.\")\n",
        "\n",
        "        if not reference_audio:\n",
        "            raise ValueError(\"Please provide a reference audio file for voice cloning.\")\n",
        "\n",
        "        try:\n",
        "            # Clear any cached states\n",
        "            torch.cuda.empty_cache() if torch.cuda.is_available() else None\n",
        "\n",
        "            # For now, since this model doesn't have built-in voice cloning,\n",
        "            # we'll try a different approach - use the reference audio to\n",
        "            # influence the generation (this is a workaround)\n",
        "\n",
        "            # Load and analyze reference audio\n",
        "            ref_audio, sr = librosa.load(reference_audio, sr=24000)\n",
        "\n",
        "            # Use basic TTS with different parameters to simulate voice adaptation\n",
        "            # In a real implementation, you'd extract voice embeddings from ref_audio\n",
        "            formatted_text = f\"[2]{text}\"  # Use speaker 2 as \"cloned\" voice\n",
        "\n",
        "            inputs = self.processor(formatted_text, add_special_tokens=True, return_tensors=\"pt\").to(self.device)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                # Generate with different parameters to try to get variation\n",
        "                audio = self.model.generate(\n",
        "                    input_ids=inputs['input_ids'],\n",
        "                    output_audio=True,\n",
        "                    do_sample=True,\n",
        "                    temperature=0.9,  # Higher temperature for more variation\n",
        "                    top_k=50,\n",
        "                    top_p=0.95,\n",
        "                    pad_token_id=self.processor.tokenizer.eos_token_id\n",
        "                )\n",
        "\n",
        "            audio_np = audio[0].cpu().numpy()\n",
        "            if len(audio_np.shape) > 1:\n",
        "                audio_np = audio_np.squeeze()\n",
        "\n",
        "            # Note: This is a simplified implementation\n",
        "            # Real voice cloning would require:\n",
        "            # 1. Voice encoder to extract speaker embeddings from reference\n",
        "            # 2. Model architecture that accepts speaker embeddings as conditioning\n",
        "            # 3. Training on speaker adaptation tasks\n",
        "\n",
        "            return 24000, audio_np\n",
        "\n",
        "        except Exception as e:\n",
        "            raise ValueError(f\"Error in voice cloning: {str(e)}\")\n",
        "\n",
        "# Initialize the TTS interface\n",
        "tts_interface = MarvisTTSInterface()\n",
        "\n",
        "# Gradio Interface Functions\n",
        "def load_model_interface():\n",
        "    \"\"\"Load model interface for Gradio\"\"\"\n",
        "    return tts_interface.load_model()\n",
        "\n",
        "def basic_tts_interface(text: str, speaker_id: int):\n",
        "    \"\"\"Basic TTS interface for Gradio with file saving\"\"\"\n",
        "    try:\n",
        "        if not text.strip():\n",
        "            return None, None, \"Please enter some text to synthesize.\"\n",
        "\n",
        "        sample_rate, audio = tts_interface.generate_basic_tts(text, speaker_id)\n",
        "\n",
        "        # Save the audio file\n",
        "        saved_file = tts_interface.save_audio_file(audio, sample_rate, \"basic_tts\")\n",
        "\n",
        "        return (sample_rate, audio), saved_file, f\"‚úÖ Audio generated and saved to: {saved_file}\"\n",
        "    except Exception as e:\n",
        "        return None, None, f\"‚ùå Error: {str(e)}\"\n",
        "\n",
        "def streaming_tts_interface(text: str, speaker_id: int):\n",
        "    \"\"\"Real-time streaming TTS interface for Gradio\"\"\"\n",
        "    try:\n",
        "        if not text.strip():\n",
        "            return None, None, \"Please enter some text to synthesize.\"\n",
        "\n",
        "        # Collect all streaming chunks for concatenation\n",
        "        audio_chunks = []\n",
        "        chunk_outputs = []\n",
        "\n",
        "        # Generate and yield each chunk in real-time\n",
        "        for i, (sample_rate, chunk) in enumerate(tts_interface.generate_streaming_tts(text, speaker_id)):\n",
        "            audio_chunks.append(chunk)\n",
        "\n",
        "            # Yield individual chunk for real-time playback\n",
        "            chunk_outputs.append((sample_rate, chunk.copy()))\n",
        "\n",
        "            # Create a temporary concatenated version for progress\n",
        "            if len(audio_chunks) > 1:\n",
        "                partial_audio = np.concatenate(audio_chunks)\n",
        "            else:\n",
        "                partial_audio = chunk\n",
        "\n",
        "            # Yield both the individual chunk and the growing concatenated audio\n",
        "            yield (sample_rate, chunk.copy()), (sample_rate, partial_audio.copy()), f\"‚úÖ Generated chunk {i+1}...\"\n",
        "\n",
        "        # Final concatenated audio\n",
        "        if audio_chunks:\n",
        "            full_audio = np.concatenate(audio_chunks)\n",
        "            yield (sample_rate, audio_chunks[-1]), (sample_rate, full_audio), f\"‚úÖ Streaming complete! Generated {len(audio_chunks)} chunks.\"\n",
        "        else:\n",
        "            yield None, None, \"‚ùå No audio generated.\"\n",
        "\n",
        "    except Exception as e:\n",
        "        yield None, None, f\"‚ùå Error: {str(e)}\"\n",
        "\n",
        "def streaming_tts_interface_simple(text: str, speaker_id: int):\n",
        "    \"\"\"Simplified streaming interface that returns final concatenated result with file saving\"\"\"\n",
        "    try:\n",
        "        if not text.strip():\n",
        "            return None, None, \"Please enter some text to synthesize.\"\n",
        "\n",
        "        # Collect all streaming chunks\n",
        "        audio_chunks = []\n",
        "        chunk_count = 0\n",
        "\n",
        "        for sample_rate, chunk in tts_interface.generate_streaming_tts(text, speaker_id):\n",
        "            audio_chunks.append(chunk)\n",
        "            chunk_count += 1\n",
        "\n",
        "        # Concatenate all chunks for final output\n",
        "        if audio_chunks:\n",
        "            full_audio = np.concatenate(audio_chunks)\n",
        "\n",
        "            # Save the complete streaming audio\n",
        "            saved_file = tts_interface.save_audio_file(full_audio, sample_rate, \"streaming_tts\")\n",
        "\n",
        "            return (sample_rate, full_audio), saved_file, f\"‚úÖ Streaming audio generated and saved! ({chunk_count} chunks) - File: {saved_file}\"\n",
        "        else:\n",
        "            return None, None, \"‚ùå No audio generated.\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return None, None, f\"‚ùå Error: {str(e)}\"\n",
        "\n",
        "def voice_cloning_interface(text: str, reference_audio):\n",
        "    \"\"\"Voice cloning interface for Gradio with file saving\"\"\"\n",
        "    try:\n",
        "        if not text.strip():\n",
        "            return None, None, \"Please enter some text to synthesize.\"\n",
        "\n",
        "        if reference_audio is None:\n",
        "            return None, None, \"Please upload a reference audio file.\"\n",
        "\n",
        "        sample_rate, audio = tts_interface.generate_voice_cloned_tts(text, reference_audio)\n",
        "\n",
        "        # Save the voice cloned audio\n",
        "        saved_file = tts_interface.save_audio_file(audio, sample_rate, \"voice_cloned\")\n",
        "\n",
        "        return (sample_rate, audio), saved_file, f\"‚úÖ Voice variation audio generated and saved to: {saved_file}\"\n",
        "\n",
        "    except Exception as e:\n",
        "        return None, None, f\"‚ùå Error: {str(e)}\"\n",
        "\n",
        "# Create Gradio Interface\n",
        "def create_gradio_interface():\n",
        "    \"\"\"Create the main Gradio interface\"\"\"\n",
        "\n",
        "    with gr.Blocks(title=\"Marvis TTS - Enhanced Interface\", theme=gr.themes.Soft()) as interface:\n",
        "\n",
        "        gr.Markdown(\"\"\"\n",
        "        # üéôÔ∏è Marvis TTS - Enhanced Interface\n",
        "\n",
        "        A powerful text-to-speech system with streaming and voice cloning capabilities.\n",
        "\n",
        "        **Features:**\n",
        "        - üöÄ Real-time streaming TTS\n",
        "        - üé≠ Voice cloning with reference audio\n",
        "        - üîä High-quality 24kHz audio output\n",
        "        - üíª GPU acceleration support\n",
        "        \"\"\")\n",
        "\n",
        "        # Model Loading Section\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                load_btn = gr.Button(\"üîÑ Load Marvis TTS Model\", variant=\"primary\")\n",
        "                model_status = gr.Textbox(label=\"Model Status\", interactive=False)\n",
        "\n",
        "        load_btn.click(fn=load_model_interface, outputs=model_status)\n",
        "\n",
        "        # Main TTS Tabs\n",
        "        with gr.Tabs():\n",
        "\n",
        "            # Basic TTS Tab\n",
        "            with gr.TabItem(\"üéØ Basic TTS\"):\n",
        "                with gr.Row():\n",
        "                    with gr.Column():\n",
        "                        basic_text = gr.Textbox(\n",
        "                            label=\"Text to Synthesize\",\n",
        "                            placeholder=\"Enter text here...\",\n",
        "                            lines=3\n",
        "                        )\n",
        "                        basic_speaker = gr.Slider(\n",
        "                            label=\"Speaker ID\",\n",
        "                            minimum=0,\n",
        "                            maximum=3,\n",
        "                            value=0,\n",
        "                            step=1\n",
        "                        )\n",
        "                        basic_generate_btn = gr.Button(\"üó£Ô∏è Generate Speech\", variant=\"primary\")\n",
        "\n",
        "                    with gr.Column():\n",
        "                        basic_audio_output = gr.Audio(label=\"Generated Audio\")\n",
        "                        basic_download_file = gr.File(label=\"üíæ Download Audio File\", visible=True)\n",
        "                        basic_status = gr.Textbox(label=\"Status\", interactive=False)\n",
        "\n",
        "                basic_generate_btn.click(\n",
        "                    fn=basic_tts_interface,\n",
        "                    inputs=[basic_text, basic_speaker],\n",
        "                    outputs=[basic_audio_output, basic_download_file, basic_status]\n",
        "                )\n",
        "\n",
        "            # Streaming TTS Tab\n",
        "            with gr.TabItem(\"‚ö° Streaming TTS\"):\n",
        "                gr.Markdown(\"\"\"\n",
        "                **Real-time Streaming**: Audio is generated and played back in chunks as they're created.\n",
        "                \"\"\")\n",
        "                with gr.Row():\n",
        "                    with gr.Column():\n",
        "                        streaming_text = gr.Textbox(\n",
        "                            label=\"Text to Synthesize (will be streamed)\",\n",
        "                            placeholder=\"Enter longer text for streaming demo...\",\n",
        "                            lines=4\n",
        "                        )\n",
        "                        streaming_speaker = gr.Slider(\n",
        "                            label=\"Speaker ID\",\n",
        "                            minimum=0,\n",
        "                            maximum=3,\n",
        "                            value=0,\n",
        "                            step=1\n",
        "                        )\n",
        "                        with gr.Row():\n",
        "                            streaming_generate_btn = gr.Button(\"üì° Start Streaming\", variant=\"primary\")\n",
        "                            streaming_simple_btn = gr.Button(\"üîÑ Generate Full Audio\", variant=\"secondary\")\n",
        "\n",
        "                    with gr.Column():\n",
        "                        # Real-time streaming output\n",
        "                        gr.Markdown(\"**üéµ Current Chunk (Real-time)**\")\n",
        "                        streaming_chunk_output = gr.Audio(label=\"Current Audio Chunk\", autoplay=True)\n",
        "\n",
        "                        # Full concatenated output\n",
        "                        gr.Markdown(\"**üíæ Full Audio (Downloadable)**\")\n",
        "                        streaming_full_output = gr.Audio(label=\"Complete Streamed Audio\")\n",
        "                        streaming_download_file = gr.File(label=\"üíæ Download Complete Audio\", visible=True)\n",
        "\n",
        "                        streaming_status = gr.Textbox(label=\"Status\", interactive=False)\n",
        "\n",
        "                # Real-time streaming with chunks\n",
        "                streaming_generate_btn.click(\n",
        "                    fn=streaming_tts_interface,\n",
        "                    inputs=[streaming_text, streaming_speaker],\n",
        "                    outputs=[streaming_chunk_output, streaming_full_output, streaming_status]\n",
        "                )\n",
        "\n",
        "                # Simple full generation\n",
        "                streaming_simple_btn.click(\n",
        "                    fn=streaming_tts_interface_simple,\n",
        "                    inputs=[streaming_text, streaming_speaker],\n",
        "                    outputs=[streaming_full_output, streaming_download_file, streaming_status]\n",
        "                )\n",
        "\n",
        "            # Voice Cloning Tab\n",
        "            with gr.TabItem(\"üé≠ Voice Cloning\"):\n",
        "                gr.Markdown(\"\"\"\n",
        "                ‚ö†Ô∏è **Note**: This model doesn't have built-in voice cloning capabilities.\n",
        "                This tab demonstrates a simplified approach using different generation parameters.\n",
        "                Real voice cloning would require a model trained specifically for speaker adaptation.\n",
        "                \"\"\")\n",
        "                with gr.Row():\n",
        "                    with gr.Column():\n",
        "                        clone_text = gr.Textbox(\n",
        "                            label=\"Text to Synthesize\",\n",
        "                            placeholder=\"Enter text to speak in a different voice style...\",\n",
        "                            lines=3\n",
        "                        )\n",
        "                        reference_audio = gr.Audio(\n",
        "                            label=\"Reference Audio (for analysis - limited effect)\",\n",
        "                            type=\"filepath\"\n",
        "                        )\n",
        "                        clone_generate_btn = gr.Button(\"üé™ Generate with Voice Variation\", variant=\"primary\")\n",
        "\n",
        "                    with gr.Column():\n",
        "                        clone_audio_output = gr.Audio(label=\"Generated Audio\")\n",
        "                        clone_download_file = gr.File(label=\"üíæ Download Audio File\", visible=True)\n",
        "                        clone_status = gr.Textbox(label=\"Status\", interactive=False)\n",
        "\n",
        "                clone_generate_btn.click(\n",
        "                    fn=voice_cloning_interface,\n",
        "                    inputs=[clone_text, reference_audio],\n",
        "                    outputs=[clone_audio_output, clone_download_file, clone_status]\n",
        "                )\n",
        "\n",
        "        # File Management Section\n",
        "        with gr.Accordion(\"üìÅ File Management\", open=False):\n",
        "            gr.Markdown(f\"\"\"\n",
        "            **Output Directory**: `{tts_interface.output_dir}/`\n",
        "\n",
        "            All generated audio files are automatically saved with timestamps:\n",
        "            - **Basic TTS**: `basic_tts_YYYYMMDD_HHMMSS.wav`\n",
        "            - **Streaming TTS**: `streaming_tts_YYYYMMDD_HHMMSS.wav`\n",
        "            - **Voice Variation**: `voice_cloned_YYYYMMDD_HHMMSS.wav`\n",
        "\n",
        "            Files are saved locally and available for download via the file components above.\n",
        "            \"\"\")\n",
        "\n",
        "        # Information Section\n",
        "        with gr.Accordion(\"‚ÑπÔ∏è Information & Tips\", open=False):\n",
        "            gr.Markdown(\"\"\"\n",
        "            ### Usage Tips:\n",
        "\n",
        "            **Basic TTS:**\n",
        "            - Choose different speaker IDs (0-3) for voice variety\n",
        "            - Optimal for short to medium length texts\n",
        "\n",
        "            **Streaming TTS:**\n",
        "            - üéµ **Real-time chunks**: Individual chunks play as they're generated (with autoplay)\n",
        "            - üíæ **Full audio**: Complete concatenated audio available for download\n",
        "            - üîÑ **Two modes**: Real-time streaming or full generation\n",
        "            - ‚è±Ô∏è **Smart chunking**: Automatically splits long text into ~8-second segments\n",
        "\n",
        "            **Voice Cloning:**\n",
        "            - ‚ö†Ô∏è **Important**: This model doesn't have true voice cloning capabilities\n",
        "            - The \"voice cloning\" tab uses different generation parameters for voice variation\n",
        "            - Real voice cloning requires specialized model architecture and training\n",
        "            - Upload reference audio to analyze characteristics (limited effect)\n",
        "\n",
        "            ### Technical Details:\n",
        "            - Sample Rate: 24,000 Hz\n",
        "            - Model: Marvis TTS 250M parameters\n",
        "            - Architecture: Conversational Speech Model (CSM)\n",
        "            - Codec: Kyutai's mimi codec with RVQ tokens\n",
        "            \"\"\")\n",
        "\n",
        "    return interface\n",
        "\n",
        "# Launch the interface\n",
        "if __name__ == \"__main__\":\n",
        "    interface = create_gradio_interface()\n",
        "    interface.launch(\n",
        "        share=True,  # Create shareable link\n",
        "        debug=True,  # Enable debug mode\n",
        "        server_port=7860  # Default Gradio port\n",
        "    )"
      ]
    }
  ]
}